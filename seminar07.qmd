---
title: "Seminar 07"
subtitle: "MA22004"
date: "2024-10-30"
author: "Dr Eric Hall   •   ehall001@dundee.ac.uk"
format: 
  revealjs:
    chalkboard: true
    html-math-method: katex
    theme: [default, resources/custom.scss]
    css: resources/fonts.css
    logo: resources/logo.png
    footer: ""
    template-partials:
      - resources/title-slide.html
    transition: slide
    background-transition: fade
from: markdown+emoji
lang: en
---

```{r}
#| include: false
knitr::opts_chunk$set(echo = FALSE, comment = "", fig.asp = .5)
library(tidyverse)
library(latex2exp)
library(openintro)
library(knitr)
library(kableExtra)
library(fontawesome)

df <- read_csv("data/anova-salaries.csv")
df$nation <- factor(df$nation)


data(hsb2)
lsz <- 1.0
tsz <- 4
theme_ur <- theme(legend.justification = c(1,1), legend.position = c(1,1), legend.box.margin = margin(c(4, 4, 4, 4), unit = "pt"))
theme_lr <- theme(legend.justification = c(1,0), legend.position = c(1,0), legend.box.margin = margin(c(4, 4, 4, 4), unit = "pt"))
```

# Announcements {.mySegue .center}
:::{.hidden}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\E}{\mathbf{E}}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\corr}{corr}
\newcommand{\se}{\mathsf{se}}
\DeclareMathOperator{\sd}{sd}
:::

## Attendance

::: {layout="[[-1], [1], [-1]]"}
![](images/seats.png){fig-align="center" fig-alt="Register your attendance using SEAtS"}
:::

## Reminders 

- Discuss worksheet 6 at Thu workshop. 
- Mock exam **Fri 2024-11-01** at **15:00**, Perth Rd Accountancy. 

## Special Announcement `r fa("bullhorn")` `r fa("bullhorn")` `r fa("bullhorn")`

EMS Invited Lecture will take place on 

**Friday, 15 Nov 2024, at 15:00 in Fulton F20** 

(tea served from 14:00 in common room)

Speaker: Prof Anna-Karin Tornberg, KTH Stockholm

## `r fa("compass")` Outline of today

1. Comparing many means

2. `R` ANOVA demo


# Comparing many means {.mySegue .center}

## Groups and treatments

We would like to consider $k$ groups/treatment populations

with means $\mu_1, \dots, \mu_k$. 

Based on samples from these $k$ groups, how can we determine whether the means are equal across each of the groups?

:::{.callout-note}
## Main idea

Test procedure based on comparing a measure of difference in variation among the sample means to a measure of variation within each sample. 
:::

## Variability partitioning

We consider different factors that contribute to variability in our response variable. 

:::{.callout-tip}
## In a few weeks, you will take your exam. 

What are some factors that might influence one's performance on an exam?
:::

## Sources of variability 

A number of factors might influence performance:

- Hours spent studying
- Completing all components (worksheets, labs, perusall)
- Pre-exposure (to testing)

## Partitioning variability 

If we wanted to consider how strongly completing all components might influence performance, we can partition variability in performance (score) into:

- variability due to completing all components and 
- variability due to all other factors (explanatory variables).

## Salary Data {.smaller}
Average Salary Data reported from 20 local councils.

```{r}
#| warning: false
#| label: tbl-salary
#| tbl-colwidths: [20,65,5,5,5]
dattab <- df |>
 group_by(nation) |>
 summarise(observations = list(mean_salary), n = n(), means = signif(mean(mean_salary), digits = 4), ssds = signif(sd(mean_salary), digits = 4))
kbl(dattab, col.names = c('Nation', "Avg salaries ('000 £)", 'Size', 'Mean', 'Sd'), align = c("l", "l", "c", "c", "c"), format = "markdown") 
```   

:::{.callout-tip}
## What ... 

...are our groups? ...means might we compare? ...question might we want to ask?
:::

:::{.notes}
- $k = 4$ groups are each nation. 
- Compare the mean salary in each nation.
- Ask if the true mean salaries are different across each nation (i.e. if the observed difference is due to chance)
:::

## Salary data: exploratory analysis

```{r}
df2 <- rbind(df,  tibble(nation = rep("UK", 20), mean_salary = df$mean_salary))
df2$nation <- factor(df2$nation, levels = c("UK", "England", "Scotland", "N Ireland", "Wales"))

# boxplot
ggplot(df2, aes(x = nation, y = mean_salary)) + 
  geom_boxplot() + 
  geom_point(aes(color = nation)) + 
  xlab("Nation") + 
  ylab("Avg (mean) salary") + 
  ggtitle("Avg salary data reported by 20 local councils") +
  theme_classic() +
  theme(legend.position = "none") 
```


## Variability partitioning : salary data

:::{.notes}
- Partition "total variability" into: 
- (.1) variabilty due to nation (between group var) and 
- (.2) variability due to all other factors (within group var -- nuissance factor)
:::

## Salary data : hypothesis test {.smaller}

$H_0 : \text{the average salary is the same accross all nations}$ ($\mu_{S} = \mu_{E} = \mu_{NI} = \mu_{W}$)

$H_a : \text{the average salaries differ between at least one pair of nations}$

```{r}
#| message: false
totrow <- df |> summarise(nation = "UK", n = n(), means = signif(mean(mean_salary), digits = 4), ssds = signif(sd(mean_salary), digits = 4))
dattab <- df |>
 group_by(nation) |>
 summarise(n = n(), means = signif(mean(mean_salary), digits = 4), ssds = signif(sd(mean_salary), digits = 4)) |>
   add_row(totrow)

kbl(dattab, col.names = c('Nation', 'Size', 'Mean', 'Sd'), align = c("l", "c", "c", "c"), format="markdown")
```  

## Test statistic

$$F = \frac{\mathsf{MSTr}}{\mathsf{MSE}}$$

</br>

:::{.callout-warning}
## Where have we seen that before?
:::

:::{.notes}
- Ratio of between and within group variabilities.
- $\mathsf{MSTr}$ = $\mathsf{SSTr} / \text{df}_{\mathsf{Tr}}$ and $\mathsf{MSE}$ = $\mathsf{SSE} / \text{df}_{\mathsf{E}}$ 
:::

## Computing test statistic {.smaller}

1. Sum of squares total (measures total variation in response variable)
$$\mathsf{SST} = \sum_{i=1}^m (x_i - \overline{x})^2$$

2. Sum of squares treatment/group (measures variability between groups)
$$\mathsf{SSTr} = \sum_{j=1}^k m_j (\overline{x}_j - \overline{x})^2$$

3. Sum of squares error (measures variability within groups) 
$$\mathsf{SSE} = \mathsf{SST} - \mathsf{SSTr}$$


:::{.notes}
- (.1) sq dev from mean of response
- (.2) sq dev from group means from mean of response, weighted by sample size [explained variability: var in response explained by factors/explanatory variables]
- (.3) i.e. unexplained variation
- (.2) as percent of (1) : percent of variation in response (mean salary) as explained by nation; remainder is not explained by variation in nation.
:::

## Computing test statistic (dof)

To go from sum of squares to mean sum of squares, we need to scale calculations with respect to sample size. 

1) total degrees of freedom:  $\text{df}_{\mathsf{T}} = m - 1$
2) treatment/group degrees of freedom:  $\text{df}_{\mathsf{Tr}} = k-1$
3) error degrees of freedom: $\text{df}_{\mathsf{E}} = \text{df}_{\mathsf{T}} - \text{df}_{\mathsf{Tr}} = m - k$

:::{.notes}
- (.1) sample size - 1
- (.2) number groups - 1
:::

## Test statistic and $P$-value {.smaller}

$$F = \frac{\mathsf{MSTr}}{\mathsf{MSE}} = \frac{\mathsf{SSTr}/\text{df}_{\mathsf{Tr}}}{\mathsf{SSE} / \text{df}_{\mathsf{E}}}$$

$P$-value area under $\mathsf{F} (\text{df}_{\mathsf{Tr}}, \text{df}_{\mathsf{E}} )$ to the right of computed statistic $f$. 

```{r}
#| echo: true
#| eval: false
pf(obsf, dfTr, dfE, lower.tail = FALSE)
```

- If $P$-value is small, we reject null hypothesis (i.e. we have sufficient evidence that at least one pair of population means are different from each other at level $\alpha$)

- If $P$-value is large, we fail to reject null hypothesis (i.e. the data do not provide convincing evidence that at least one pair of population means are different from each other: the observed difference in the sample means are attributed to sampling variability)

:::{.notes}
- Even though we are considering difference we only consider upper tail of $\mathsf{F}$ b/c $f$ can never be negative (ratio of two positive measures of variation)
:::

## Conditions for ANOVA

1.  Independence 
    -  within groups
    -  between groups (i.e. NOT paired)
2. Approximately normal
    - How could one check this?
3. Equal variance (homoscedasticity)


# `R` ANOVA demo {.mySegue .center}


# Summary

Today we discussed single factor anova.

- Idea behind the test statistic (partitioning variability)
- Calculating test statistic
- Concluding hypothesis test
- Conditions for anova

That's a lot to take in!

:::{.callout-tip}
## Today's materials 

Slides posted to <https://dundeemath.github.io/MA22004-seminar07>.
:::